{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d7b0cd",
   "metadata": {},
   "source": [
    "![Ambient Provider](images/ambientprovider.png)\n",
    "\n",
    "# Ambient Provider Getting Started Guide\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "- [Ambient Provider](#ambient-provider)\n",
    "  - [Summary](#summary)\n",
    "  - [Key Capabilities](#key-capabilities)\n",
    "  - [System Architecture](#system-architecture)\n",
    "- [Getting Started](#getting-started)\n",
    "  - [Prerequisites at a Glance](#prerequisites-at-a-glance)\n",
    "  - [NGC Account](#ngc-account)\n",
    "  - [HW Requirements](#hw-requirements)\n",
    "  - [Docker Installation](#docker-installation)\n",
    "  - [NVIDIA NIM Deployment](#nvidia-nim-deployment)\n",
    "  - [Dataset Download](#dataset-download)\n",
    "  - [Installation](#installation)\n",
    "- [Using the Platform](#using-the-platform)\n",
    "    - [Basic workflow](#basic-workflow)\n",
    "    - [Advanced Features](#advanced-features)\n",
    "---\n",
    "\n",
    "# Important: Git Submodule Setup\n",
    "\n",
    "⚠️⚠️  **Before proceeding, make sure to pull the git submodule first:**  ⚠️ ⚠️ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88c055b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'ambient-provider' (git@github.com:NVIDIA-AI-Blueprints/ambient-provider.git) registered for path 'ambient-provider'\n",
      "Cloning into '/home/ubuntu/ambient-healthcare-agents/ambient-provider'...\n",
      "Submodule path 'ambient-provider': checked out 'edaae19a3ccad6314f1715d244928b63648f3fda'\n"
     ]
    }
   ],
   "source": [
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c44aa8",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Ambient Provider is a comprehensive platform that converts audio recordings of medical consultations into structured clinical notes. The system uses NVIDIA NIM (NVIDIA Inference Microservices) for accurate speech recognition with speaker diarization, combined with reasoning large language models to generate medical documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f0de4",
   "metadata": {},
   "source": [
    "# Prerequisite Setup\n",
    "There are two key components to this transcription workflow:\n",
    "1) The NVIDIA NIM ASR transcription services with diarization (Parakeet model)\n",
    "2) The [llama-3.3-nemotron-super-49b-v1](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1) reasoning model. \n",
    "\n",
    "This getting started guide will help you set up the necessary hardware and api keys to be able to run the ambient provider developer example.\n",
    "\n",
    "### Prerequisites at a Glance\n",
    "The bullet points below highlight an overview of the steps in this getting started guide:\n",
    "- **Setup NGC account**: Setting up account to download resources\n",
    "- **Ensure valid HW**: Confirm your system has the required HW\n",
    "- **Install Docker & NVIDIA Container Toolkit**: Enable GPU support for containers\n",
    "- **Deploy NIM**: Launch NVIDIA NIM for ASR and diarization\n",
    "- **Install SW**: Clone the repository and establish environment\n",
    "\n",
    "### Key Requirements\n",
    "1. **Hardware Requirements**:\n",
    "   - NVIDIA GPU with 16GB+ VRAM (for NVIDIA Riva ie: NVIDIA RTX, T4, L4)\n",
    "\n",
    "2. **Software Requirements**:\n",
    "   - Docker & Docker Compose v2.0+\n",
    "   - Git (for cloning repository)\n",
    "   - npm (Node Package Manager)\n",
    "\n",
    "3. **API Keys**:\n",
    "   - NVIDIA API Key (from NGC)\n",
    "   - Network access to NVIDIA Riva deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6d2d3",
   "metadata": {},
   "source": [
    "### NGC Account\n",
    "Setup an account on [NGC](https://ngc.nvidia.com) using the procedure in the [NGC user guide](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html). \n",
    "\n",
    "This is needed in order to obtain the necessary NGC API key credentials required to pull the [Riva Speech Skills SDK](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/containers/riva-speech) container and access the cloud api endpoints.\n",
    "\n",
    "Once your NGC credentials and Cloud account is setup, follow the details below to obtain the NGC_API_KEY to be able to access the [NVIDIA API catalog endpoints](https://build.nvidia.com) (AI Models, etc.). \n",
    "\n",
    "### Generate an API Key\n",
    "To access NGC resources, you need an NGC API key:\n",
    "\n",
    "1. Visit [NGC Personal Key Generation](https://org.ngc.nvidia.com/setup/personal-keys)\n",
    "2. Create a new API key\n",
    "3. Ensure \"NGC Catalog\" is selected from the \"Services Included\" dropdown\n",
    "4. Copy the generated API key\n",
    "\n",
    "### Export the API Key\n",
    "Make the NGC API key available to Docker:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9885ca63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NGC_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca61ddd-27ec-438e-8b79-e7c1887dcd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"NGC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ee5c1-b315-4ca7-9149-0d60a5f8aa8a",
   "metadata": {},
   "source": [
    "## Prepare Your Machine\n",
    "\n",
    "### Docker\n",
    "Install [Docker](https://docs.docker.com/engine/install/) on your system. Check to ensure the installation worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4331e473-4459-4989-bf16-1b7be2a7cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker version 28.4.0, build d8eb465\n"
     ]
    }
   ],
   "source": [
    "!docker -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d0e1d",
   "metadata": {},
   "source": [
    "### NVIDIA Container Toolkit\n",
    "Install the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-the-nvidia-container-toolkit) to enable GPU support in Docker containers.\n",
    "\n",
    "After installing the toolkit, follow the instructions in the Configure Docker section in the NVIDIA Container Toolkit [documentation.](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-docker)\n",
    "\n",
    "### Verify Installation\n",
    "Test your setup with the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3782d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'ubuntu:latest' locally\n",
      "latest: Pulling from library/ubuntu\n",
      "\n",
      "\u001b[1BDigest: sha256:fdb6c9ceb1293dcb0b7eda5df195b15303b01857d7b10f98489e7691d20aa2a1\n",
      "Status: Downloaded newer image for ubuntu:latest\n",
      "Thu Oct  2 23:11:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    On  |   00000000:30:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             21W /  350W |       0MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53682e",
   "metadata": {},
   "source": [
    "This should produce output similar to:\n",
    "```\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:1B:00.0 Off |                    0 |\n",
    "| N/A   36C    P0            112W /  700W |   78489MiB /  81559MiB |      0%      Default |\n",
    "|                                         |                        |             Disabled |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "```\n",
    "\n",
    "### Docker Login to NGC\n",
    "Authenticate with the NVIDIA Container Registry:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "869a0ac8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/home/ubuntu/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!echo \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2e614",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "## 1. Setup the virtual environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46667e6e-de8a-42cf-9968-76e4740f89f8",
   "metadata": {},
   "source": [
    "If the uv package manager is not installed, please install with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3773c806-9cbf-4dbc-8275-e9cf9b92e2cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading uv 0.8.22 x86_64-unknown-linux-gnu\n",
      "no checksums to verify\n",
      "installing to /home/ubuntu/.local/bin\n",
      "  uv\n",
      "  uvx\n",
      "everything's installed!\n",
      "uv 0.8.22\n"
     ]
    }
   ],
   "source": [
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "os.environ[\"PATH\"] = os.path.expanduser(\"~/.local/bin\") + \":\" + os.environ[\"PATH\"]\n",
    "!uv --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7702efec-b3d9-40d5-8f19-f46718d8efdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease   \n",
      "Hit:3 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease \n",
      "Get:4 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease [1477 B]\n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:6 https://repos.influxdata.com/debian stable InRelease                     \n",
      "Hit:7 https://download.docker.com/linux/ubuntu jammy InRelease                 \n",
      "Hit:8 https://apt.grafana.com stable InRelease                                 \n",
      "Hit:9 https://apt.corretto.aws stable InRelease                                \n",
      "Hit:10 https://fsx-lustre-client-repo.s3.amazonaws.com/ubuntu jammy InRelease  \n",
      "Hit:11 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Fetched 1477 B in 1s (2205 B/s)\n",
      "Reading package lists... Done\n",
      "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/archive_uri-https_developer_download_nvidia_com_compute_cuda_repos_ubuntu2204_x86_64_-jammy.list:1 and /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list:1\n",
      "W: Target Translations (en) is configured multiple times in /etc/apt/sources.list.d/archive_uri-https_developer_download_nvidia_com_compute_cuda_repos_ubuntu2204_x86_64_-jammy.list:1 and /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list:1\n",
      "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/archive_uri-https_developer_download_nvidia_com_compute_cuda_repos_ubuntu2204_x86_64_-jammy.list:1 and /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list:1\n",
      "W: Target Translations (en) is configured multiple times in /etc/apt/sources.list.d/archive_uri-https_developer_download_nvidia_com_compute_cuda_repos_ubuntu2204_x86_64_-jammy.list:1 and /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list:1\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  alsa-topology-conf alsa-ucm-conf libasound2 libasound2-data libasound2-dev\n",
      "  libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
      "Suggested packages:\n",
      "  libasound2-plugins alsa-utils libasound2-doc jackd1 portaudio19-doc\n",
      "The following NEW packages will be installed:\n",
      "  alsa-topology-conf alsa-ucm-conf libasound2 libasound2-data libasound2-dev\n",
      "  libjack-dev libjack0 libportaudio2 libportaudiocpp0 portaudio19-dev\n",
      "0 upgraded, 10 newly installed, 0 to remove and 29 not upgraded.\n",
      "Need to get 1064 kB of archives.\n",
      "After this operation, 6797 kB of additional disk space will be used.\n",
      "Get:1 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/main amd64 alsa-topology-conf all 1.2.5.1-2 [15.5 kB]\n",
      "Get:2 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-data all 1.2.6.1-1ubuntu1 [19.1 kB]\n",
      "Get:3 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/main amd64 libasound2 amd64 1.2.6.1-1ubuntu1 [390 kB]\n",
      "Get:4 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy-updates/main amd64 alsa-ucm-conf all 1.2.6.3-1ubuntu1.12 [43.5 kB]\n",
      "Get:5 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-dev amd64 1.2.6.1-1ubuntu1 [110 kB]\n",
      "Get:6 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/universe amd64 libjack0 amd64 1:0.125.0-3build2 [93.3 kB]\n",
      "Get:7 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/universe amd64 libjack-dev amd64 1:0.125.0-3build2 [206 kB]\n",
      "Get:8 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
      "Get:9 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
      "Get:10 http://us-east-1.ec2.archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
      "Fetched 1064 kB in 0s (10.8 MB/s)        \n",
      "Selecting previously unselected package alsa-topology-conf.\n",
      "(Reading database ... 109753 files and directories currently installed.)\n",
      "Preparing to unpack .../0-alsa-topology-conf_1.2.5.1-2_all.deb ...\n",
      "Unpacking alsa-topology-conf (1.2.5.1-2) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../1-libasound2-data_1.2.6.1-1ubuntu1_all.deb ...\n",
      "Unpacking libasound2-data (1.2.6.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../2-libasound2_1.2.6.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.2.6.1-1ubuntu1) ...\n",
      "Selecting previously unselected package alsa-ucm-conf.\n",
      "Preparing to unpack .../3-alsa-ucm-conf_1.2.6.3-1ubuntu1.12_all.deb ...\n",
      "Unpacking alsa-ucm-conf (1.2.6.3-1ubuntu1.12) ...\n",
      "Selecting previously unselected package libasound2-dev:amd64.\n",
      "Preparing to unpack .../4-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libjack0:amd64.\n",
      "Preparing to unpack .../5-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
      "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
      "Selecting previously unselected package libjack-dev.\n",
      "Preparing to unpack .../6-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
      "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
      "Selecting previously unselected package libportaudio2:amd64.\n",
      "Preparing to unpack .../7-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Selecting previously unselected package libportaudiocpp0:amd64.\n",
      "Preparing to unpack .../8-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
      "Selecting previously unselected package portaudio19-dev:amd64.\n",
      "Preparing to unpack .../9-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
      "Setting up libasound2-data (1.2.6.1-1ubuntu1) ...\n",
      "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
      "Setting up alsa-topology-conf (1.2.5.1-2) ...\n",
      "Setting up libasound2:amd64 (1.2.6.1-1ubuntu1) ...\n",
      "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
      "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
      "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Setting up alsa-ucm-conf (1.2.6.3-1ubuntu1.12) ...\n",
      "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
      "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
      "NEEDRESTART-VER: 3.5\n",
      "NEEDRESTART-KCUR: 6.8.0-1036-aws\n",
      "NEEDRESTART-KEXP: 6.8.0-1036-aws\n",
      "NEEDRESTART-KSTA: 1\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y portaudio19-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb132675",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ambient-healthcare-agents/ambient-provider\n",
      "Using CPython \u001b[36m3.13.7\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
      "\u001b[2mResolved \u001b[1m157 packages\u001b[0m \u001b[2min 0.70ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m14 packages\u001b[0m \u001b[2min 5.93s\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m151 packages\u001b[0m \u001b[2min 209ms\u001b[0m\u001b[0m                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.12.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannoy\u001b[0m\u001b[2m==1.17.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maudioop-lts\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maudioread\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdotenv\u001b[0m\u001b[2m==0.9.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.118.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastembed\u001b[0m\u001b[2m==0.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mffmpy\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==25.9.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.31.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgreenlet\u001b[0m\u001b[2m==3.2.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgroovy\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-tools\u001b[0m\u001b[2m==1.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.1.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.35.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpatch\u001b[0m\u001b[2m==1.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpointer\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.3.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.3.30\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.77\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.4.31\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlazy-loader\u001b[0m\u001b[2m==0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlibrosa\u001b[0m\u001b[2m==0.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mllvmlite\u001b[0m\u001b[2m==0.45.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==4.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsgpack\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.6.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnemoguardrails\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumba\u001b[0m\u001b[2m==0.62.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-riva-client\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.81.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.11.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpooch\u001b[0m\u001b[2m==1.8.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy-rust-stemmers\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyaudio\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydub\u001b[0m\u001b[2m==0.25.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafehttpx\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msemantic-version\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==70.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msimpleeval\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoundfile\u001b[0m\u001b[2m==0.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoxr\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlalchemy\u001b[0m\u001b[2m==2.0.43\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstandard-aifc\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstandard-chunk\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstandard-sunau\u001b[0m\u001b[2m==3.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.48.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==9.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.35.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwatchdog\u001b[0m\u001b[2m==6.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.20.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.25.0\u001b[0m\n",
      "/home/ubuntu/ambient-healthcare-agents/ambient-provider/ambient-scribe\n"
     ]
    }
   ],
   "source": [
    "%cd ambient-provider\n",
    "!uv venv --clear\n",
    "!uv sync\n",
    "%cd ambient-scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055be00f",
   "metadata": {},
   "source": [
    "## 2. Download the medical conversation dataset\n",
    "The dataset example used in this workflow can be obtained from [Hugging Face](https://huggingface.co/datasets/yfyeung/medical) and consists of simulated patient-physician interactions. Download the dataset into a sub-directory called \"dataset\" that is parallel in scope to the ambient-scribe directory. Be sure to unzip the dataset.\n",
    "\n",
    "## 3. Bootstrap the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076d154-2d92-4ace-b3a2-3b9bba618d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "The following command:\n",
    "- Creates necessary directories\n",
    "- Sets up environment files\n",
    "- Validates dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb44df2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!make bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5785b86",
   "metadata": {},
   "source": [
    "## 4. Deploy Riva and the Ambient Provider\n",
    "\n",
    "You have two options for deploying NVIDIA NIM:\n",
    "\n",
    "### Option 1: RIVA Integrated with Docker Compose (Recommended)\n",
    "The easiest way is to use the built-in NIM profile that's integrated with the application:\n",
    "\n",
    "#### Configure environment variables:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810ad2c-f720-4676-b430-cf029bf9418c",
   "metadata": {},
   "source": [
    "If you do not see the hidden .env file in jupyter lab, please modify the file within a terminal session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e476bac7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the API configuration\n",
    "# nano apps/api/.env\n",
    "\n",
    "# Add the following configuration:\n",
    "# NVIDIA API Configuration (Required)\n",
    "# NVIDIA_API_KEY=your_nvidia_api_key_here\n",
    "# RIVA_URI=parakeet-nim:50051"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd7910",
   "metadata": {},
   "source": [
    "#### Deploy the dev environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb4bec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Development with local NIM\n",
    "!make dev-nim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff44be5",
   "metadata": {},
   "source": [
    "### Option 2: Standalone NIM Deployment\n",
    "Deploy the Parakeet 1.1b English ASR model manually with speaker diarization support:\n",
    "\n",
    "This option is primarily if you intend to deploy the riva container on a separate machine as your ambient provider. If you deploy riva outside of the docker network of ambient provider on the same machine, you may experience difficulties communicating between your riva and ambient provider applications due to firewall rules.\n",
    "\n",
    "#### On the separate machine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce63ebc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set container configuration\n",
    "export CONTAINER_ID=parakeet-1-1b-ctc-en-us\n",
    "export NIM_TAGS_SELECTOR=\"name=parakeet-1-1b-ctc-en-us,mode=all\"\n",
    "\n",
    "# Launch the NIM container\n",
    "docker run -d --rm --name=$CONTAINER_ID \\\n",
    "   --runtime=nvidia \\\n",
    "   --gpus '\"device=0\"' \\\n",
    "   --shm-size=8GB \\\n",
    "   -e NGC_API_KEY \\\n",
    "   -e NIM_HTTP_API_PORT=9000 \\\n",
    "   -e NIM_GRPC_API_PORT=50051 \\\n",
    "   -p 9000:9000 \\\n",
    "   -p 50051:50051 \\\n",
    "   -e NIM_TAGS_SELECTOR \\\n",
    "   nvcr.io/nim/nvidia/$CONTAINER_ID:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919962d9",
   "metadata": {},
   "source": [
    "For Option 2, configure your environment to point to your separate Riva machine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2f331",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Edit the API configuration\n",
    "# nano apps/api/.env\n",
    "\n",
    "# Add the following configuration:\n",
    "# NVIDIA API Configuration (Required)  \n",
    "# NVIDIA_API_KEY=your_nvidia_api_key_here\n",
    "# RIVA_URI=<YOUR_RIVA_IP>:50051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fd65b-fc0e-4a1e-807c-9758b3220bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then deploy without local NIM\n",
    "# make dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefe71d",
   "metadata": {},
   "source": [
    "#### Verify NIM Deployment\n",
    "Check that the NIM container is running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aaa5b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker ps | grep parakeet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b7a6d",
   "metadata": {},
   "source": [
    "You should see output similar to:\n",
    "```\n",
    "a1b2c3d4e5f6   nvcr.io/nim/nvidia/parakeet-1-1b-ctc-en-us:latest   \"/opt/nvidia/nvidia_…\"   2 minutes ago   Up 2 minutes   0.0.0.0:9000->9000/tcp, 0.0.0.0:50051->50051/tcp   parakeet-1-1b-ctc-en-us\n",
    "```\n",
    "\n",
    "The NIM will be accessible at:\n",
    "- **HTTP API**: http://localhost:9000\n",
    "- **gRPC API**: localhost:50051\n",
    "\n",
    "> **Note:** After starting the NIM container, check the container logs to ensure you see a message indicating that Riva is running and listening on port 9000. If you do not see this message, the Riva NIM may still be starting up. You can view the logs with:\n",
    ">\n",
    "> ```bash\n",
    "> docker logs -f $CONTAINER_ID\n",
    "> ```\n",
    ">\n",
    "> Wait until you see confirmation that the service is running on port 9000 before proceeding.\n",
    "\n",
    "## 5. Access the applications\n",
    "Please note if you are using brev, please follow step 6 to either expose the port as a secure link or create an ngrok tunnel. \n",
    "\n",
    "- **UI**: http://localhost:5173\n",
    "- **API Documentation**: http://localhost:8000/api/docs\n",
    "- **Health Check**: http://localhost:8000/api/health\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf304d5",
   "metadata": {},
   "source": [
    "## 6. Enable port access\n",
    "- **Brev**: If your cloud service provider enables exposing a port through the UI like in brev, you may specify to expose TCP/UDP traffic to port 5173 for this quick start guide. \n",
    "- **ngrok**: If you cannot expose ports directly, you can use [ngrok](https://ngrok.com/) to create a secure tunnel to your local development environment.\n",
    "\n",
    "### Using ngrok for remote access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9fdad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install ngrok (if not already installed)\n",
    "sudo snap install ngrok\n",
    "\n",
    "# Add your ngrok authtoken (get from ngrok.com dashboard)\n",
    "ngrok config add-authtoken <YOUR_NGROK_AUTHTOKEN>\n",
    "\n",
    "# Expose your local port (e.g., 5173 for the UI)\n",
    "ngrok http 5173"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317ef7b",
   "metadata": {},
   "source": [
    "# Using the Platform\n",
    "![ambientprovider UI](../images/ambient_provider_ui.png)\n",
    "\n",
    "## Basic Workflow\n",
    "\n",
    "1. **Upload Audio File**:\n",
    "   - Drag and drop an audio file (MP3, WAV, M4A, FLAC)\n",
    "   - Supported formats are automatically validated\n",
    "   - Maximum file size: 100MB (configurable)\n",
    "\n",
    "2. **Transcription Process**:\n",
    "   - Audio is converted to 16kHz mono WAV format\n",
    "   - NVIDIA Riva processes with speaker diarization\n",
    "   - Transcript segments are created with timestamps and speaker tags\n",
    "\n",
    "3. **Select Note Template**:\n",
    "   - Choose from available templates:\n",
    "     - **SOAP Default**: Standard Subjective, Objective, Assessment, Plan format\n",
    "     - **Progress Note**: For follow-up visits\n",
    "     - **Custom templates**: Created by your organization\n",
    "\n",
    "4. **Generate Medical Note**:\n",
    "   - AI processes the transcript using the selected template\n",
    "   - Real-time progress is shown with processing traces\n",
    "   - Note sections are generated and displayed incrementally\n",
    "\n",
    "5. **Edit and Refine**:\n",
    "   - Use the rich text editor to modify content\n",
    "   - Citations automatically link note content to transcript segments\n",
    "   - Autocomplete suggests content from the transcript\n",
    "\n",
    "6. **Export and Save**:\n",
    "   - Copy note to clipboard\n",
    "   - Save for future reference\n",
    "   - Export in various formats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942ccda",
   "metadata": {},
   "source": [
    "## How to Convert Between Streaming and Offline Transcription\n",
    "To switch between streaming and offline transcription modes, you need to update both the frontend and backend environment configuration files:\n",
    "\n",
    "1. **Frontend**:  \n",
    "   - Go into your frontend environment file (e.g., `.env`).\n",
    "   - Find the setting that enables streaming (e.g., `VITE_ENABLE_STREAMING=true`) and change it to `false`:\n",
    "     ```\n",
    "     VITE_ENABLE_STREAMING=false\n",
    "     ```\n",
    "\n",
    "2. **Backend**:  \n",
    "   - Open your backend environment file (e.g., `.env`).\n",
    "   - Change `ENABLE_STREAMING=true` to `ENABLE_STREAMING=false`.\n",
    "   - Update the Riva model name to use the offline model by replacing the word `streaming` with `offline` in the `RIVA_MODEL` variable. For example:\n",
    "     ```\n",
    "     ENABLE_STREAMING=false\n",
    "     RIVA_MODEL=parakeet-1.1b-en-US-asr-offline-silero-vad-sortformer\n",
    "     ```\n",
    "   - Make sure to restart both the frontend and backend services after making these changes. If you have a dev deployment the system will restart automatically.\n",
    "\n",
    "## Use hosted NIM\n",
    "To use the hosted NIM (NVIDIA Inference Microservice) instead of a self-hosted Riva deployment, you need to update your backend environment configuration:\n",
    "\n",
    "1. **Set `SELF_HOSTED` to `false`**  \n",
    "   In your backend `.env` file, change:\n",
    "   ```\n",
    "   SELF_HOSTED=false\n",
    "   ```\n",
    "\n",
    "2. **Update the Riva Function ID**  \n",
    "   Replace the `RIVA_FUNCTION_ID` value with the function ID provided by NVIDIA for your hosted NIM instance:\n",
    "   ```\n",
    "   RIVA_FUNCTION_ID=your_hosted_nim_function_id_here\n",
    "   ```\n",
    "\n",
    "3. **Set the Riva URI to the NVIDIA GRP URL**  \n",
    "   Update the `RIVA_URI` to point to the NVIDIA hosted endpoint, for example:\n",
    "   ```\n",
    "   RIVA_URI=grp.nvidia.com:443\n",
    "   ```\n",
    "\n",
    "Make sure to restart your backend service after making these changes for them to take effect.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
